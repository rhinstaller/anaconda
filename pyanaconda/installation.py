# install.py
# Do the hard work of performing an installation.
#
# Copyright (C) 2012  Red Hat, Inc.
#
# This copyrighted material is made available to anyone wishing to use,
# modify, copy, or redistribute it subject to the terms and conditions of
# the GNU General Public License v.2, or (at your option) any later version.
# This program is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY expressed or implied, including the implied warranties of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.  You should have received a copy of the
# GNU General Public License along with this program; if not, write to the
# Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
# 02110-1301, USA.  Any Red Hat trademarks that are incorporated in the
# source code or documentation are not subject to the GNU General Public
# License and may only be used or replicated with the express permission of
# Red Hat, Inc.
#
from pyanaconda.core.dbus import DBus
from pyanaconda.core.configuration.anaconda import conf
from pyanaconda.core.constants import PAYLOAD_LIVE_TYPES, PAYLOAD_TYPE_DNF
from pyanaconda.modules.common.constants.objects import BOOTLOADER, SNAPSHOT, FIREWALL
from pyanaconda.modules.common.constants.services import STORAGE, USERS, SERVICES, NETWORK, \
    SECURITY, LOCALIZATION, TIMEZONE, BOSS, SUBSCRIPTION
from pyanaconda.modules.common.task import sync_run_task
from pyanaconda.modules.common.util import is_module_available
from pyanaconda.progress import progress_message, progress_step, progress_complete, progress_init
from pyanaconda import flags
from pyanaconda.core import util
from pyanaconda import timezone
from pyanaconda import network
from pyanaconda.core.i18n import N_
from pyanaconda.threading import threadMgr
from pyanaconda.kickstart import runPostScripts, runPreInstallScripts
from pyanaconda.kexec import setup_kexec
from pyanaconda.installation_tasks import Task, TaskQueue, DBusTask
from pykickstart.constants import SNAPSHOT_WHEN_POST_INSTALL

from pyanaconda.anaconda_loggers import get_module_logger
log = get_module_logger(__name__)

__all__ = ["run_installation"]


class WriteResolvConfTask(Task):
    """Custom task subclass for handling the resolv.conf copy task.

    The main reason is to resolve the sysroot path right before the
    copy operation, not at task & task queue creation time.

    Secondary reason is to demonstrate how a lightweight Task subclass can be used.
    """

    def run_task(self):
        """Resolve the sysroot path only right before doing the copy operation.

        If we just added the sysroot path as an argument, it would be resolved when the
        task queue was created, not when the task is actually executed, which could
        theoretically result in an incorrect path.
        """
        network.copy_resolv_conf_to_root(conf.target.system_root)


def _writeKS(ksdata):
    path = conf.target.system_root + "/root/anaconda-ks.cfg"

    # Make it so only root can read - could have passwords
    with util.open_with_perm(path, "w", 0o600) as f:
        f.write("# Generated by Anaconda {}\n".format(util.get_anaconda_version_string()))
        f.write(str(ksdata))


def _copy_logs(*args):
    """Copy installation logs to the target system.

    The code is based on the 99-copy-logs.ks post script which is replaced by this.
    """
    import os.path
    import shutil
    import glob

    def copy_file_if_exists(src, dest):
        if os.path.exists(src):
            shutil.copyfile(src, dest)

    log.info("Copying logs from the installation environment...")

    if conf.anaconda.save_logs:
        util.mkdirChain(conf.target.system_root + "/var/log/anaconda/")
        # copy log files from the list
        LOG_FILES_TO_COPY = [
            "anaconda.log", "syslog", "X.log", "program.log", "packaging.log", "storage.log",
            "ifcfg.log", "lvm.log", "dnf.librepo.log", "hawkey.log", "dbus.log"
        ]
        for logfile in LOG_FILES_TO_COPY:
            src_path = "/tmp/" + logfile
            dest_path = conf.target.system_root + "/var/log/anaconda/" + logfile
            copy_file_if_exists(src_path, dest_path)
        # copy logs from %pre scripts
        PRE_ANA_LOGS = "/tmp/pre-anaconda-logs"
        if os.path.exists(PRE_ANA_LOGS):
            shutil.copytree(PRE_ANA_LOGS,
                            conf.target.system_root + "/var/log/anaconda/")
        # copy DNF debug data (if any)
        DNF_DEBUG_LOGS = "/root/debugdata"
        if os.path.exists(DNF_DEBUG_LOGS):
            shutil.copytree(DNF_DEBUG_LOGS,
                            conf.target.system_root + "/var/log/anaconda/dnf_debugdata/")
        # copy logs from %post scripts
        for logfile in glob.glob("/tmp/ks-script*.log"):
            shutil.copyfile(logfile,
                            conf.target.system_root + "/var/log/anaconda/" + os.path.basename(logfile))
        # dump journal
        with open(conf.target.system_root + "/var/log/anaconda/journal.log", "w") as logfile:
            util.execWithRedirect("journalctl", ["-b"], stdout=logfile)
        copy_file_if_exists("/root/lorax-packages.log",
                            conf.target.system_root + "/var/log/anaconda/lorax-packages.log")
        # set access bits
        util.execInSysroot("bash", ["-c", "chmod 0600 /var/log/anaconda/*"])

    log.info("Done.")

    log.info("Copying generated kickstart file...")

    if not conf.anaconda.save_input_kickstart:
        log.info("Nosave used, skipping.")
    else:
        copy_file_if_exists("/run/install/ks.cfg",
                            conf.target.system_root + "/root/original-ks.cfg")
        log.info("Done.")

    # Relabel the anaconda logs we've just copied, since they could be incorrectly labeled, like
    # hawkey.log: https://bugzilla.redhat.com/show_bug.cgi?id=1885772.
    util.execInSysroot("restorecon", ["-ir", "/var/log/anaconda/"])


def _prepare_configuration(payload, ksdata):
    """Configure the installed system."""

    configuration_queue = TaskQueue("Configuration queue")
    # connect progress reporting
    configuration_queue.queue_started.connect(lambda x: progress_message(x.status_message))
    configuration_queue.task_completed.connect(lambda x: progress_step(x.name))

    # add installation tasks for the Subscription DBus module
    if is_module_available(SUBSCRIPTION):
        # we only run the tasks if the Subscription module is available
        subscription_config = TaskQueue("Subscription configuration",
                                        N_("Configuring Red Hat subscription"))
        subscription_proxy = SUBSCRIPTION.get_proxy()
        subscription_dbus_tasks = subscription_proxy.InstallWithTasks()
        subscription_config.append_dbus_tasks(SUBSCRIPTION, subscription_dbus_tasks)
        configuration_queue.append(subscription_config)

    # schedule the execute methods of ksdata that require an installed system to be present
    os_config = TaskQueue("Installed system configuration", N_("Configuring installed system"))

    # add installation tasks for the Security DBus module
    if is_module_available(SECURITY):
        security_proxy = SECURITY.get_proxy()
        security_dbus_tasks = security_proxy.InstallWithTasks()
        os_config.append_dbus_tasks(SECURITY, security_dbus_tasks)

    # add installation tasks for the Timezone DBus module
    # run these tasks before tasks of the Services module
    if is_module_available(TIMEZONE):
        timezone_proxy = TIMEZONE.get_proxy()
        timezone_dbus_tasks = timezone_proxy.InstallWithTasks()
        os_config.append_dbus_tasks(TIMEZONE, timezone_dbus_tasks)

    # add installation tasks for the Services DBus module
    if is_module_available(SERVICES):
        services_proxy = SERVICES.get_proxy()
        services_dbus_tasks = services_proxy.InstallWithTasks()
        os_config.append_dbus_tasks(SERVICES, services_dbus_tasks)

    # add installation tasks for the Localization DBus module
    if is_module_available(LOCALIZATION):
        localization_proxy = LOCALIZATION.get_proxy()
        localization_dbus_tasks = localization_proxy.InstallWithTasks()
        os_config.append_dbus_tasks(LOCALIZATION, localization_dbus_tasks)

    # add the Firewall configuration task
    if conf.target.can_configure_network:
        firewall_proxy = NETWORK.get_proxy(FIREWALL)
        firewall_dbus_task = firewall_proxy.InstallWithTask()
        os_config.append_dbus_tasks(NETWORK, [firewall_dbus_task])

    configuration_queue.append(os_config)

    # schedule network configuration (if required)
    if conf.target.can_configure_network and conf.system.provides_network_config:
        overwrite = payload.type in PAYLOAD_LIVE_TYPES
        network_config = TaskQueue("Network configuration", N_("Writing network configuration"))
        network_config.append(Task("Network configuration",
                                   network.write_configuration, (overwrite, )))
        configuration_queue.append(network_config)

    # add installation tasks for the Users DBus module
    if is_module_available(USERS):
        user_config = TaskQueue("User creation", N_("Creating users"))
        users_proxy = USERS.get_proxy()
        users_dbus_tasks = users_proxy.InstallWithTasks()
        user_config.append_dbus_tasks(USERS, users_dbus_tasks)
        configuration_queue.append(user_config)

    # Anaconda addon configuration
    addon_config = TaskQueue("Anaconda addon configuration", N_("Configuring addons"))

    boss_proxy = BOSS.get_proxy()
    for service_name, object_path in boss_proxy.CollectInstallSystemTasks():
        task_proxy = DBus.get_proxy(service_name, object_path)
        addon_config.append(DBusTask(task_proxy))

    configuration_queue.append(addon_config)

    # Initramfs generation
    generate_initramfs = TaskQueue("Initramfs generation", N_("Generating initramfs"))
    bootloader_proxy = STORAGE.get_proxy(BOOTLOADER)

    def run_generate_initramfs():
        tasks = bootloader_proxy.GenerateInitramfsWithTasks(
            payload.type,
            payload.kernel_version_list
        )

        for task in tasks:
            sync_run_task(STORAGE.get_proxy(task))

    generate_initramfs.append(Task("Generate initramfs", run_generate_initramfs))
    configuration_queue.append(generate_initramfs)

    if is_module_available(SECURITY):
        security_proxy = SECURITY.get_proxy()

        # Configure FIPS.
        configuration_queue.append_dbus_tasks(SECURITY, [security_proxy.ConfigureFIPSWithTask()])

        # Join a realm. This can run only after network is configured in the target system chroot.
        configuration_queue.append_dbus_tasks(SECURITY, [security_proxy.JoinRealmWithTask()])

    # setup kexec reboot if requested
    if flags.flags.kexec:
        kexec_setup = TaskQueue("Kexec setup", N_("Setting up kexec"))
        kexec_setup.append(Task("Setup kexec", setup_kexec))
        configuration_queue.append(kexec_setup)

    # write anaconda related configs & kickstarts
    write_configs = TaskQueue(
        "Write configs and kickstarts",
        N_("Storing configuration files and kickstarts")
    )

    # Write the kickstart file to the installed system (or, copy the input
    # kickstart file over if one exists).
    if not conf.anaconda.save_output_kickstart:
        # don't write the kickstart file to the installed system if this has
        # been disabled by the nosave option
        log.warning("Writing of the output kickstart to installed system has been disabled"
                    " by the nosave option.")
    else:
        # write anaconda related configs & kickstarts
        write_configs.append(Task("Store kickstarts", _writeKS, (ksdata,)))

    # only add write_configs to the main queue if we actually store some kickstarts/configs
    if write_configs.task_count:
        configuration_queue.append(write_configs)

    post_scripts = TaskQueue(
        "Post installation scripts",
        N_("Running post-installation scripts")
    )
    post_scripts.append(Task(
        "Run post installation scripts",
        runPostScripts,
        (ksdata.scripts,)
    ))
    configuration_queue.append(post_scripts)

    copy_logs = TaskQueue(
        "Copy logs",
        N_("Copying logs")
    )
    copy_logs.append(Task(
        "Copy installation logs",
        _copy_logs,
        (None,)
    ))
    configuration_queue.append(copy_logs)

    return configuration_queue


def _prepare_installation(payload, ksdata):
    """Perform an installation.  This method takes the ksdata as prepared by
       the UI (the first hub, in graphical mode) and applies it to the disk.
       The two main tasks for this are putting filesystems onto disks and
       installing packages onto those filesystems.
    """
    installation_queue = TaskQueue("Installation queue")
    # connect progress reporting
    installation_queue.queue_started.connect(lambda x: progress_message(x.status_message))
    installation_queue.task_completed.connect(lambda x: progress_step(x.name))

    # This should be the only thread running, wait for the others to finish if not.
    if threadMgr.running > 1:
        # it could be that the threads finish execution before the task is executed,
        # but that should not cause any issues

        def wait_for_all_treads():
            for message in ("Thread %s is running" % n for n in threadMgr.names):
                log.debug(message)
            threadMgr.wait_all()

        # Use a queue with a single task as only TaskQueues have the status_message
        # property used for setting the progress status in the UI.
        wait_for_threads = TaskQueue(
            "Wait for threads to finish",
            N_("Waiting for %s threads to finish") % (threadMgr.running - 1)
        )

        wait_for_threads.append(Task("Wait for all threads to finish", wait_for_all_treads))
        installation_queue.append(wait_for_threads)

    # Save system time to HW clock.
    # - this used to be before waiting on threads, but I don't think that's needed
    if conf.system.can_set_hardware_clock:
        # lets just do this as a top-level task - no
        save_hwclock = Task("Save system time to HW clock", timezone.save_hw_clock)
        installation_queue.append(save_hwclock)

    # setup the installation environment
    setup_environment = TaskQueue(
        "Installation environment setup",
        N_("Setting up the installation environment")
    )

    boss_proxy = BOSS.get_proxy()
    for service_name, object_path in boss_proxy.CollectConfigureRuntimeTasks():
        task_proxy = DBus.get_proxy(service_name, object_path)
        setup_environment.append(DBusTask(task_proxy))

    # Add configuration tasks for the Localization DBus module.
    if is_module_available(LOCALIZATION):
        localization_proxy = LOCALIZATION.get_proxy()
        # Populate the missing keyboard values before the payload installation,
        # so the module requirements can be generated for the right configuration.
        # FIXME: Make sure that the module always returns right values.
        populate_task = localization_proxy.PopulateMissingKeyboardConfigurationWithTask()
        setup_environment.append_dbus_tasks(LOCALIZATION, [populate_task])

    installation_queue.append(setup_environment)

    # Do partitioning.
    # Depending on current payload the storage might be apparently configured
    # either before or after package/payload installation.
    # So let's have two task queues - early storage & late storage.
    storage_proxy = STORAGE.get_proxy()
    early_storage = TaskQueue("Early storage configuration", N_("Configuring storage"))
    early_storage.append_dbus_tasks(STORAGE, storage_proxy.InstallWithTasks())

    if payload.type == PAYLOAD_TYPE_DNF:
        conf_task = storage_proxy.WriteConfigurationWithTask()
        early_storage.append_dbus_tasks(STORAGE, [conf_task])

    installation_queue.append(early_storage)

    # Run %pre-install scripts with the filesystem mounted and no packages
    pre_install_scripts = TaskQueue("Pre-install scripts", N_("Running pre-installation scripts"))
    pre_install_scripts.append(Task(
        "Run %pre-install scripts",
        runPreInstallScripts, (ksdata.scripts,)
    ))
    installation_queue.append(pre_install_scripts)

    # Do various pre-installation tasks
    # - try to discover a realm (if any)
    # - check for possibly needed additional packages.
    pre_install = TaskQueue("Pre install tasks", N_("Running pre-installation tasks"))

    # make name resolution work for rpm scripts in chroot
    if conf.system.provides_resolver_config:
        # we use a custom Task subclass as the sysroot path has to be resolved
        # only when the task is actually started, not at task creation time
        pre_install.append(WriteResolvConfTask("Copy resolv.conf to sysroot"))

    if is_module_available(SECURITY):
        security_proxy = SECURITY.get_proxy()

        # Discover a realm.
        pre_install.append_dbus_tasks(SECURITY, [security_proxy.DiscoverRealmWithTask()])

        # Set up FIPS for the payload installation.
        fips_task = security_proxy.PreconfigureFIPSWithTask(payload.type)
        pre_install.append_dbus_tasks(SECURITY, [fips_task])

    # Install the payload.
    pre_install.append(Task("Find additional packages & run pre_install()", payload.pre_install))
    installation_queue.append(pre_install)

    payload_install = TaskQueue("Payload installation", N_("Installing."))
    payload_install.append(Task("Install the payload", payload.install))
    installation_queue.append(payload_install)

    # for some payloads storage is configured after the payload is installed
    if payload.type != PAYLOAD_TYPE_DNF:
        late_storage = TaskQueue("Late storage configuration", N_("Configuring storage"))
        conf_task = storage_proxy.WriteConfigurationWithTask()
        late_storage.append_dbus_tasks(STORAGE, [conf_task])
        installation_queue.append(late_storage)

    # Do bootloader.
    bootloader_proxy = STORAGE.get_proxy(BOOTLOADER)
    bootloader_install = TaskQueue("Bootloader installation", N_("Installing boot loader"))

    def run_configure_bootloader():
        tasks = boss_proxy.CollectConfigureBootloaderTasks(
            payload.kernel_version_list
        )

        for service, task in tasks:
            sync_run_task(DBus.get_proxy(service, task))

    bootloader_install.append(Task("Configure bootloader", run_configure_bootloader))

    def run_install_bootloader():
        tasks = bootloader_proxy.InstallBootloaderWithTasks(
            payload.type,
            payload.kernel_version_list
        )

        for task in tasks:
            sync_run_task(STORAGE.get_proxy(task))

    bootloader_install.append(Task("Install bootloader", run_install_bootloader))
    installation_queue.append(bootloader_install)

    post_install = TaskQueue(
        "Post-installation setup tasks",
        (N_("Performing post-installation setup tasks"))
    )
    post_install.append(Task("Run post-installation setup tasks", payload.post_install))
    installation_queue.append(post_install)

    # Create snapshot
    snapshot_proxy = STORAGE.get_proxy(SNAPSHOT)

    if snapshot_proxy.IsRequested(SNAPSHOT_WHEN_POST_INSTALL):
        snapshot_creation = TaskQueue(
            "Creating post installation snapshots",
            N_("Creating snapshots")
        )
        snapshot_task = snapshot_proxy.CreateWithTask(SNAPSHOT_WHEN_POST_INSTALL)
        snapshot_creation.append_dbus_tasks(STORAGE, [snapshot_task])
        installation_queue.append(snapshot_creation)

    return installation_queue


def run_installation(payload, ksdata):
    """Run the complete installation."""
    queue = TaskQueue("Complete installation queue")
    queue.append(_prepare_installation(payload, ksdata))
    queue.append(_prepare_configuration(payload, ksdata))

    # notify progress tracking about the number of steps
    progress_init(queue.task_count)

    # log contents of the main task queue
    log.info(queue.summary)

    # log tasks and queues when they are started
    # - note that we are using generators to add the counter
    queue_counter = util.item_counter(queue.queue_count)
    task_started_counter = util.item_counter(queue.task_count)
    task_completed_counter = util.item_counter(queue.task_count)
    queue.queue_started.connect(
        lambda x: log.info("Queue started: %s (%s)", x.name, next(queue_counter))
    )
    queue.task_started.connect(
        lambda x: log.info("Task started: %s (%s)", x.name, next(task_started_counter))
    )
    queue.task_completed.connect(
        lambda x: log.debug("Task completed: %s (%s) (%1.1f s)", x.name,
                            next(task_completed_counter), x.elapsed_time)
    )

    # start the task queue
    queue.start()

    # done
    progress_complete()
    # this message is automatically detected by QE tools, do not change it lightly
    log.info("All tasks in the installation queue are done. Installation successfully finished.")
